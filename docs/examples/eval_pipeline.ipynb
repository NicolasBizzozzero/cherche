{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Semanlink automatic tagging, evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook present how to evaluate a neural search pipeline using pairs of query and answers. We will try to automatically tag arxiv papers that were manually automated by François-Paul Servant as part of [Semanlink](http://www.semanlink.net/sl/home?lang=fr) knowledge graph."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pprint import pprint as print\n",
    "from cherche import data, rank, retrieve, eval\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, query_answers = data.arxiv_tags(arxiv_title=True, arxiv_summary=False, comment=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `documents` contain a list of tags, each tag is represented as a dict and contains a set of attributes. We will try to automate the tagging of arxiv documents with a neural search pipeline that will retrieve tags based on their attributes using the title, abstract and comments of the arxiv articles as a query."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the list of attributes each tag has:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'altLabel': [],\n",
      " 'altLabel_text': '',\n",
      " 'broader': ['http://www.semanlink.net/tag/statistical_classification',\n",
      "             'http://www.semanlink.net/tag/embeddings'],\n",
      " 'broader_altLabel': ['embedding'],\n",
      " 'broader_altLabel_text': 'embedding',\n",
      " 'broader_prefLabel': ['Classification', 'Embeddings'],\n",
      " 'broader_prefLabel_text': 'Classification Embeddings',\n",
      " 'broader_related': ['http://www.semanlink.net/tag/nlp_techniques',\n",
      "                     'http://www.semanlink.net/tag/similarity_queries'],\n",
      " 'comment': 'How to embed (describe) classes (in classification)? See related '\n",
      "            'work section of this '\n",
      "            '[paper](doc:2020/02/joint_embedding_of_words_and_la)\\r\\n'\n",
      "            '\\r\\n'\n",
      "            '> [FastText](tag:fasttext) generates both word\\r\\n'\n",
      "            'embeddings and label embeddings. It seeks to predict one of the '\n",
      "            'document’s labels (instead of the central\\r\\n'\n",
      "            'word) ([src](doc:2020/10/1911_11506_word_class_embeddi))',\n",
      " 'creationDate': '2020-02-18',\n",
      " 'creationTime': '2020-02-18T15:00:36Z',\n",
      " 'describedBy': [],\n",
      " 'homepage': '',\n",
      " 'linkToMusicBrainz': '',\n",
      " 'prefLabel': ['Label Embedding'],\n",
      " 'prefLabel_text': 'Label Embedding',\n",
      " 'publish': '',\n",
      " 'related': ['http://www.semanlink.net/tag/fasttext'],\n",
      " 'sameAs': [],\n",
      " 'seeAlso': '',\n",
      " 'subject': '',\n",
      " 'type': ['http://www.semanlink.net/2001/00/semanlink-schema#Tag'],\n",
      " 'uri': 'http://www.semanlink.net/tag/label_embedding',\n",
      " 'weblog': '',\n",
      " 'wikipage-en': ''}\n"
     ]
    }
   ],
   "source": [
    "print(documents[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what a query looks likes using `arxiv title`, `arxiv summary` and `comments`. We will try to find the right document (tag) for this query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "' Joint Embedding of Words and Labels for Text Classification'\n"
     ]
    }
   ],
   "source": [
    "print(query_answers[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate a first piepline made of a single retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfIdf retriever\n",
       " \t on: prefLabel_text, altLabel_text\n",
       " \t documents: 433"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = retrieve.TfIdf(\n",
    "    on = [\"prefLabel_text\", \"altLabel_text\"], \n",
    "    tfidf = TfidfVectorizer(lowercase=True, min_df=1, max_df=0.9, ngram_range=(3, 7), analyzer=\"char\"), \n",
    "    k = 10,\n",
    ")\n",
    "\n",
    "retriever.add(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision@1': '63.06%',\n",
       " 'Precision@2': '43.47%',\n",
       " 'Precision@3': '33.12%',\n",
       " 'Precision@4': '26.67%',\n",
       " 'Precision@5': '22.55%',\n",
       " 'Precision@6': '19.85%',\n",
       " 'Precision@7': '17.52%',\n",
       " 'Precision@8': '15.84%',\n",
       " 'Precision@9': '14.61%',\n",
       " 'R-Precision': '26.95%',\n",
       " 'Precision': '13.47%'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.eval(search = retriever, query_answers=query_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what tagging looks like using our retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'http://www.semanlink.net/tag/nlu'\n",
      "'http://www.semanlink.net/tag/attention_is_all_you_need'\n",
      "'http://www.semanlink.net/tag/pre_trained_language_models'\n",
      "'http://www.semanlink.net/tag/nlp_pretraining'\n",
      "'http://www.semanlink.net/tag/co_training'\n",
      "'http://www.semanlink.net/tag/huggingface_transformers'\n",
      "'http://www.semanlink.net/tag/self_training'\n",
      "'http://www.semanlink.net/tag/attention_in_graphs'\n",
      "'http://www.semanlink.net/tag/sbert'\n",
      "'http://www.semanlink.net/tag/language_model'\n"
     ]
    }
   ],
   "source": [
    "tags = retriever(\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\")\n",
    "for tag in tags:\n",
    "    print(tag[\"uri\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not bad, TfIdf on title using ngrams does well. We will now try to improve those results using a ranker."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = retrieve.TfIdf(\n",
    "    on = [\"prefLabel_text\", \"altLabel_text\"], \n",
    "    tfidf = TfidfVectorizer(lowercase=True, min_df=1, max_df=0.9, ngram_range=(3, 7), analyzer=\"char\"), \n",
    "    k = 30,\n",
    ")\n",
    "\n",
    "ranker = rank.Encoder(\n",
    "    encoder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\").encode,\n",
    "    on = [\"prefLabel_text\", \"altLabel_text\"],\n",
    "    k = 10,\n",
    "    path = \"all-mpnet-base-v2.pkl\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pre-calculation of 314 queries to speed up evaluation. Transformers are slow using cpu...\n",
    "\n",
    "Pre-calculation time on cpu:\n",
    "- title: 24 seconds \n",
    "- title and summary: 6 minutes and 18 seconds\n",
    "- title, summary and comments: 8 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Encoder ranker\n",
       "\t on: prefLabel_text, altLabel_text\n",
       "\t k: 10\n",
       "\t similarity: cosine\n",
       "\t embeddings stored at: all-mpnet-base-v2.pkl"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker.add([q for q, _ in query_answers])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TfIdf retriever\n",
       " \t on: prefLabel_text, altLabel_text\n",
       " \t documents: 433\n",
       "Encoder ranker\n",
       "\t on: prefLabel_text, altLabel_text\n",
       "\t k: 10\n",
       "\t similarity: cosine\n",
       "\t embeddings stored at: all-mpnet-base-v2.pkl"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search = retriever + ranker\n",
    "search.add(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision@1': '63.69%',\n",
       " 'Precision@2': '42.83%',\n",
       " 'Precision@3': '33.01%',\n",
       " 'Precision@4': '26.75%',\n",
       " 'Precision@5': '22.55%',\n",
       " 'Precision@6': '19.53%',\n",
       " 'Precision@7': '17.56%',\n",
       " 'Precision@8': '15.88%',\n",
       " 'Precision@9': '14.37%',\n",
       " 'R-Precision': '27.43%',\n",
       " 'Precision': '13.18%'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.eval(search = search, query_answers = query_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Sentence Bert ranker improves the results of the retriever a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our tags for Bert paper using retriever ranker:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'http://www.semanlink.net/tag/pre_trained_language_models'\n",
      "'http://www.semanlink.net/tag/attention_is_all_you_need'\n",
      "'http://www.semanlink.net/tag/nlp_pretraining'\n",
      "'http://www.semanlink.net/tag/nlu'\n",
      "'http://www.semanlink.net/tag/attention_knowledge_graphs'\n",
      "'http://www.semanlink.net/tag/sbert'\n",
      "'http://www.semanlink.net/tag/grounded_language_learning'\n",
      "'http://www.semanlink.net/tag/language_models_as_knowledge_bases'\n",
      "'http://www.semanlink.net/tag/language_models_knowledge'\n",
      "'http://www.semanlink.net/tag/attention_in_graphs'\n"
     ]
    }
   ],
   "source": [
    "tags = search(\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\")\n",
    "for tag in tags:\n",
    "    print(tag[\"uri\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try to use using FlashText as a retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Flash retriever\n",
       " \t on: prefLabel, altLabel\n",
       " \t documents: 605\n",
       "Encoder ranker\n",
       "\t on: prefLabel_text, altLabel_text\n",
       "\t k: 10\n",
       "\t similarity: cosine\n",
       "\t embeddings stored at: all-mpnet-base-v2.pkl"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = retrieve.Flash(\n",
    "    on = [\"prefLabel\", \"altLabel\"], \n",
    "    k = 30,\n",
    ")\n",
    "\n",
    "ranker = rank.Encoder(\n",
    "    encoder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\").encode,\n",
    "    on = [\"prefLabel_text\", \"altLabel_text\"],\n",
    "    k = 10,\n",
    "    path = \"all-mpnet-base-v2.pkl\"\n",
    ")\n",
    "\n",
    "search = retriever + ranker\n",
    "search.add(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FlashText as a retriever provides fewer candidates than TfIdf but has higher precision."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision@1': '72.80%',\n",
       " 'Precision@2': '61.90%',\n",
       " 'Precision@3': '59.90%',\n",
       " 'Precision@4': '59.27%',\n",
       " 'Precision@5': '59.37%',\n",
       " 'Precision@6': '59.37%',\n",
       " 'Precision@7': '59.37%',\n",
       " 'Precision@8': '59.37%',\n",
       " 'Precision@9': '59.37%',\n",
       " 'R-Precision': '20.20%',\n",
       " 'Precision': '59.37%'}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.eval(search = search, query_answers = query_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'http://www.semanlink.net/tag/attention_is_all_you_need'\n",
      "'http://www.semanlink.net/tag/bert'\n"
     ]
    }
   ],
   "source": [
    "tags = search(\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\")\n",
    "for tag in tags:\n",
    "    print(tag[\"uri\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the best of both worlds by using pipeline union. It gets a bit complicated, but the union allows us to retrieve the best candidates from the first model, then add the candidates from the second model without duplicates (etc, no matter how many models are in the union). Our first retriever and ranker (Flash + Encoder) has low recall and high precision. The second retriever has lower precision but higher recall. We can mix things up and offer Flash and Ranker candidates first, then TfIdf and Ranker candidates seconds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Union Pipeline\n",
       "-----\n",
       "Flash retriever\n",
       " \t on: prefLabel, altLabel\n",
       " \t documents: 605\n",
       "Encoder ranker\n",
       "\t on: prefLabel_text, altLabel_text\n",
       "\t k: 10\n",
       "\t similarity: cosine\n",
       "\t embeddings stored at: all-mpnet-base-v2.pkl\n",
       "TfIdf retriever\n",
       " \t on: prefLabel_text, altLabel_text\n",
       " \t documents: 433\n",
       "Encoder ranker\n",
       "\t on: prefLabel_text, altLabel_text\n",
       "\t k: 10\n",
       "\t similarity: cosine\n",
       "\t embeddings stored at: all-mpnet-base-v2.pkl\n",
       "-----"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ranker = rank.Encoder(\n",
    "    encoder = SentenceTransformer(\"sentence-transformers/all-mpnet-base-v2\").encode,\n",
    "    on = [\"prefLabel_text\", \"altLabel_text\"],\n",
    "    k = 10,\n",
    "    path = \"all-mpnet-base-v2.pkl\"\n",
    ")\n",
    "\n",
    "precision = retrieve.Flash(\n",
    "    on = [\"prefLabel\", \"altLabel\"], \n",
    "    k = 30,\n",
    ") + ranker\n",
    "\n",
    "recall = retrieve.TfIdf(\n",
    "    on = [\"prefLabel_text\", \"altLabel_text\"], \n",
    "    tfidf = TfidfVectorizer(lowercase=True, min_df=1, max_df=0.9, ngram_range=(3, 7), analyzer=\"char\"), \n",
    "    k = 10,\n",
    ") + ranker\n",
    "\n",
    "search = precision | recall\n",
    "\n",
    "search.add(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Precision@1': '66.88%',\n",
       " 'Precision@2': '47.77%',\n",
       " 'Precision@3': '37.26%',\n",
       " 'Precision@4': '29.62%',\n",
       " 'Precision@5': '24.59%',\n",
       " 'Precision@6': '21.07%',\n",
       " 'Precision@7': '18.29%',\n",
       " 'Precision@8': '16.32%',\n",
       " 'Precision@9': '14.79%',\n",
       " 'R-Precision': '30.48%',\n",
       " 'Precision': '13.68%'}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval.eval(search = search, query_answers = query_answers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here are our tags for bert's article with best of both worlds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'http://www.semanlink.net/tag/attention_is_all_you_need'\n",
      "'http://www.semanlink.net/tag/bert'\n",
      "'http://www.semanlink.net/tag/pre_trained_language_models'\n",
      "'http://www.semanlink.net/tag/nlp_pretraining'\n",
      "'http://www.semanlink.net/tag/nlu'\n",
      "'http://www.semanlink.net/tag/sbert'\n",
      "'http://www.semanlink.net/tag/attention_in_graphs'\n",
      "'http://www.semanlink.net/tag/self_training'\n",
      "'http://www.semanlink.net/tag/language_model'\n",
      "'http://www.semanlink.net/tag/co_training'\n",
      "'http://www.semanlink.net/tag/huggingface_transformers'\n"
     ]
    }
   ],
   "source": [
    "tags = search(\"BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding\")\n",
    "for tag in tags:\n",
    "    print(tag[\"uri\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is what tagging looks like with my first paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'http://www.semanlink.net/tag/knowledge_base'\n",
      "'http://www.semanlink.net/tag/knowledge_distillation'\n",
      "'http://www.semanlink.net/tag/embeddings'\n",
      "'http://www.semanlink.net/tag/knowledge_graph_embeddings'\n",
      "'http://www.semanlink.net/tag/text_kg_and_embeddings'\n",
      "'http://www.semanlink.net/tag/ai_knowledge_bases'\n",
      "'http://www.semanlink.net/tag/phrase_embeddings'\n",
      "'http://www.semanlink.net/tag/knowledge_graph'\n",
      "'http://www.semanlink.net/tag/language_models_as_knowledge_bases'\n",
      "'http://www.semanlink.net/tag/bert_kb'\n",
      "'http://www.semanlink.net/tag/knowledge'\n"
     ]
    }
   ],
   "source": [
    "tags = search(\"Knowledge Base Embedding By Cooperative Knowledge Distillation\")\n",
    "for tag in tags:\n",
    "    print(tag[\"uri\"])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7b170744ab9cf7446ed3e27cb2734f2273f9ffda6b52a7d603d13471f7231bb1"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('cherche': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
